language: python
python:
- 3.6
- 3.5
- 2.7

sudo: required
cache:
  - pip: true
before_install:
  - curl -L -o spark.tgz https://s3.amazonaws.com/spark-related-packages/spark-2.2.0-bin-hadoop2.7.tgz
  - export SPARK_HOME=./local/spark
  - mkdir -p "$SPARK_HOME"
  - tar -xf spark.tgz -C "$SPARK_HOME" --strip-components=1
  - export PATH="$SPARK_HOME/bin:$PATH"
  - export SPARK_LOCAL_IP="127.0.0.1"
  # These lines here just suppress a lot of noisy log messages from Spark.
  - echo "log4j.logger.org.apache.spark=WARN" > "$SPARK_HOME"/conf/log4j.properties
  - echo "log4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR" >> "$SPARK_HOME"/conf/log4j.properties
  - echo "log4j.logger.org.apache.parquet=ERROR" >> "$SPARK_HOME"/conf/log4j.properties

install: pip install -U tox-travis
script: tox
deploy:
  provider: pypi
  distributions: sdist bdist_wheel
  user: flavianhautbois
  password:
    secure: dGCPoN7+Uj6GU9NJp+CFLLXc1Rq0QHbGROMZvNXBLrlcFMViq1ElLb0lQmsigUGmYBasUIBDPMzxF2eA0hNbADZicNgD+ZxqYxCEKiFScBaZ2kVzBGkIehzBJ2ui6WwrVUIQd/r8W3eT3hbexVpRNUeqK5+FgZ2/t+f6O0t0tXm/Ematz3rCw6ceBR0Siip5i9Vz7OXN/K8cLYFjRRoOT+f4HpVzaeTUlktd9M06G1WVbLv0VF4zm1R48ei32cbd2nObUYzKwBfDCBSlXGCp8vg/ErNDJ/QGIkKj71nL2lkqJkK2gKhFF4Fl6LUvBlEusw1U1fZkiwRhtE8D2u+5/1I5f8XgAL/wh3a6gj+gn0EmuDjiewahQEdpLBWlNwYl7SAdIjvZ/Re/vi0UB9cxW1FRL92uEOBF//twHh9yQ+9a5uDREpZAWlFQUNe0+YdbEa3n4KyGC/nQMW5hlPZGJ5JwyHP0ZJc7ihPTnNcl4lT2LeYXPBhYa/l4/D4de8vgIreTCsMFqpLatvG3q3nVtSUmhmo6nqBsUYwle6SWcNEr4/k5L+8A/Xns0L1HjQ9tADuxL0JKrS0Wfdh2qD1Xu+qo3GGqv6qclgvt64oWMfuX7DPFynZlWWkCcsR2CEs99moN+xiswtMNDbkTYBfg6BjTYoTCdOx+su+Hjj086aY=
  on:
    tags: true
    repo: flavianh/spark_etl_python
    python: 3.6
