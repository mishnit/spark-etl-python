language: python
python:
- 3.6
- 3.5
- 2.7
sudo: required
cache:
- pip: true
before_install:
- curl -L -o spark.tgz https://s3.amazonaws.com/spark-related-packages/spark-2.2.0-bin-hadoop2.7.tgz
- export SPARK_HOME=./local/spark
- mkdir -p "$SPARK_HOME"
- tar -xf spark.tgz -C "$SPARK_HOME" --strip-components=1
- export PATH="$SPARK_HOME/bin:$PATH"
- export SPARK_LOCAL_IP="127.0.0.1"
- echo "log4j.logger.org.apache.spark=WARN" > "$SPARK_HOME"/conf/log4j.properties
- echo "log4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR" >> "$SPARK_HOME"/conf/log4j.properties
- echo "log4j.logger.org.apache.parquet=ERROR" >> "$SPARK_HOME"/conf/log4j.properties
install: pip install -U tox-travis
script: tox
deploy:
  provider: pypi
  distributions: sdist bdist_wheel
  user: flavianhautbois
  password:
    secure: qPQeR/PPqjB+gVk5p8O8RzSeNVHifg/zCl2xm4ePVyEt2YrDkdufnRE8eLPypUYvgV9e+FdKQpzJ8XKMZuVa5JdQUGPlTZd/GgoyS62o8EXfyvCg71ILTqTgREpgY7AReTG/d6QqnyAR1rRCr6jHztCVTtW02rIOFXrupyqRxnMdcz16MLIjgfvPOCuO7v8TGQRj4EmyrPvpgGYBI4vCdVxE6lOSxBdRCyca9SVJTD2tLmCRxK6FLQYAJubMKjHYGVctA1t+KOzArzTRMl8Di3V6DCvBYtQr7Gk65CZarySXrubAW95D42tHOzfPY5kOuUosVJty2iuuMXL+TGMzvlxNayPQpOqTVY8xLmL+vrcankiL8bCZ4viiCU8jfzUYhg4IaSanlTNWS4ug1bHxNsWZuma362pwUsfZc+g/8v18G3nNLczolW7rsMD5eSTITHJRLZfdTSRKgrZTvS0nl9+nFlhf5s4ITkiJweNPix8aXKrD0UGRe8sMmS4inbJhUR8Hd1NsDXHXEvAdtgeN5zUL3uh75me6dKH9niSYCOo+0vMqYIiTW7qANP7/xkevq2wSas2fyFK2N8IIOZqoMtRNyZZR1Ql2ODihC3wZYg+6LpgJs76ytcssLs0AatvDWFFGfXtNeLm1y2Om/PRLh6oAHl0Vq57XKmuVVHIqkok=
  on:
    tags: true
    repo: sicara/spark-etl-python
    python: 3.6
